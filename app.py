import os
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import librosa
import librosa.display as ld
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report
from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift
import streamlit as st
import tempfile
from PIL import Image, UnidentifiedImageError
import io
import torch
import zipfile
import gc

# ==================== CONFIGURA√á√ÉO DA P√ÅGINA ====================
def main():
    # ==================== DEFINI√á√ÉO DO SEED ====================
    st.sidebar.header("Configura√ß√µes Gerais")
    
    # Adicionando a sele√ß√£o de SEED na barra lateral
    seed_options = [0, 42, 100]
    seed_selection = st.sidebar.selectbox(
        "Escolha o valor do SEED:",
        options=seed_options,
        index=1,  # 42 como valor padr√£o
        help="Define a semente para reprodutibilidade dos resultados."
    )
    
    SEED = seed_selection  # Definindo a vari√°vel SEED

    # Definir o caminho do √≠cone (favicon)
    favicon_path = "logo.png"  # Verifique se o arquivo logo.png est√° no diret√≥rio correto

    # Verificar se o arquivo de √≠cone existe antes de configur√°-lo
    if os.path.exists(favicon_path):
        try:
            st.set_page_config(
                page_title="Classifica√ß√£o de Sons de √Ågua Vibrando em Copo de Vidro",
                page_icon=favicon_path,
                layout="wide"
            )
            # logging.info(f"√çcone {favicon_path} carregado com sucesso.")  # Remova ou configure o logging se necess√°rio
        except Exception as e:
            st.set_page_config(
                page_title="Classifica√ß√£o de Sons de √Ågua Vibrando em Copo de Vidro",
                layout="wide"
            )
            st.sidebar.warning(f"Erro ao carregar o √≠cone {favicon_path}: {e}")
    else:
        # Se o √≠cone n√£o for encontrado, carrega sem favicon e exibe aviso
        st.set_page_config(
            page_title="Classifica√ß√£o de Sons de √Ågua Vibrando em Copo de Vidro",
            layout="wide"
        )
        st.sidebar.warning(f"√çcone '{favicon_path}' n√£o encontrado, carregando sem favicon.")

    # ==================== LOGO E IMAGEM DE CAPA ====================
    # Carrega e exibe a capa.png na p√°gina principal
    if os.path.exists('capa (2).png'):
        try:
            st.image(
                'capa (2).png', 
                caption='Laborat√≥rio de Educa√ß√£o e Intelig√™ncia Artificial - Geomaker. "A melhor forma de prever o futuro √© invent√°-lo." - Alan Kay', 
                use_container_width=True
            )
        except UnidentifiedImageError:
            st.warning("Imagem 'capa (2).png' n√£o p√¥de ser carregada ou est√° corrompida.")
    else:
        st.warning("Imagem 'capa (2).png' n√£o encontrada.")

    # Carregar o logotipo na barra lateral
    if os.path.exists("logo.png"):
        try:
            st.sidebar.image("logo.png", width=200, use_container_width=False)
        except UnidentifiedImageError:
            st.sidebar.text("Imagem do logotipo n√£o p√¥de ser carregada ou est√° corrompida.")
    else:
        st.sidebar.text("Imagem do logotipo n√£o encontrada.")

    st.title("Classifica√ß√£o de Sons de √Ågua Vibrando em Copo de Vidro com Aumento de Dados e CNN")
    st.write("""
    Bem-vindo √† nossa aplica√ß√£o! Aqui, voc√™ pode **classificar sons de √°gua vibrando em copos de vidro**. Voc√™ tem duas op√ß√µes:
    - **Classificar √Åudio:** Use um modelo j√° treinado para identificar o som.
    - **Treinar Modelo:** Treine seu pr√≥prio modelo com seus dados de √°udio.
    """)

    # Barra Lateral de Navega√ß√£o
    st.sidebar.title("Navega√ß√£o")
    app_mode = st.sidebar.selectbox("Escolha a se√ß√£o", ["Classificar √Åudio", "Treinar Modelo"])

    if app_mode == "Classificar √Åudio":
        classificar_audio(SEED)
    elif app_mode == "Treinar Modelo":
        treinar_modelo(SEED)
    
    # Adicionando o √≠cone na barra lateral
    if os.path.exists("eu.ico"):
        try:
            st.sidebar.image("eu.ico", width=80, use_container_width=False)
        except UnidentifiedImageError:
            st.sidebar.text("Imagem do √≠cone 'eu.ico' n√£o p√¥de ser carregada ou est√° corrompida.")
    else:
        st.sidebar.text("Imagem do √≠cone 'eu.ico' n√£o encontrada.")
    
    st.sidebar.write("""
    Produzido pelo:

    Projeto Geomaker + IA 

    https://doi.org/10.5281/zenodo.13910277

    - Professor: Marcelo Claro.

    Contatos: marceloclaro@gmail.com

    Whatsapp: (88)981587145

    Instagram: [marceloclaro.geomaker](https://www.instagram.com/marceloclaro.geomaker/)
    """)

# ==================== FUN√á√ïES DE PROCESSAMENTO ====================

augment_default = Compose([
    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),
    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),
    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),
    Shift(min_shift=-0.5, max_shift=0.5, p=0.5),
])

def carregar_audio(caminho_arquivo, sr=None):
    """
    Carrega um arquivo de √°udio.

    Parameters:
    - caminho_arquivo (str): Caminho para o arquivo de √°udio.
    - sr (int, optional): Taxa de amostragem. Se None, usa a taxa original.

    Returns:
    - data (np.ndarray): Sinal de √°udio.
    - sr (int): Taxa de amostragem.
    """
    try:
        data, sr = librosa.load(caminho_arquivo, sr=sr, res_type='kaiser_fast')
        return data, sr
    except Exception as e:
        st.error(f"Erro ao carregar o √°udio {caminho_arquivo}: {e}")
        return None, None

def extrair_features(data, sr):
    """
    Extrai os MFCCs do sinal de √°udio e calcula a m√©dia ao longo do tempo.

    Parameters:
    - data (np.ndarray): Sinal de √°udio.
    - sr (int): Taxa de amostragem.

    Returns:
    - mfccs_scaled (np.ndarray): Vetor de caracter√≠sticas MFCC.
    """
    try:
        mfccs = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40)
        mfccs_scaled = np.mean(mfccs.T, axis=0)
        return mfccs_scaled
    except Exception as e:
        st.error(f"Erro ao extrair MFCC: {e}")
        return None

def aumentar_audio(data, sr, augmentations):
    """
    Aplica Data Augmentation ao sinal de √°udio com as transforma√ß√µes selecionadas.

    Parameters:
    - data (np.ndarray): Sinal de √°udio.
    - sr (int): Taxa de amostragem.
    - augmentations (Compose): Composi√ß√£o de transforma√ß√µes de aumento.

    Returns:
    - augmented_data (np.ndarray): Sinal de √°udio aumentado.
    """
    try:
        augmented_data = augmentations(samples=data, sample_rate=sr)
        return augmented_data
    except Exception as e:
        st.error(f"Erro ao aplicar Data Augmentation: {e}")
        return data  # Retorna o original em caso de erro

def plot_forma_onda(data, sr, titulo="Forma de Onda"):
    """
    Plota a forma de onda do √°udio.

    Parameters:
    - data (np.ndarray): Sinal de √°udio.
    - sr (int): Taxa de amostragem.
    - titulo (str): T√≠tulo do gr√°fico.
    """
    fig, ax = plt.subplots(figsize=(14, 4))
    ax.set_title(titulo, fontsize=16)
    ld.waveshow(data, sr=sr, ax=ax)
    ax.set_xlabel("Tempo (segundos)", fontsize=14)
    ax.set_ylabel("Amplitude", fontsize=14)
    ax.tick_params(axis='both', which='major', labelsize=12)
    st.pyplot(fig)
    plt.close(fig)

def plot_espectro_frequencias(data, sr, titulo="Espectro de Frequ√™ncias"):
    """
    Plota o espectro de frequ√™ncias do √°udio.

    Parameters:
    - data (np.ndarray): Sinal de √°udio.
    - sr (int): Taxa de amostragem.
    - titulo (str): T√≠tulo do gr√°fico.
    """
    N = len(data)
    fft = np.fft.fft(data)
    fft = np.abs(fft[:N//2])  # Apenas a metade positiva do espectro
    freqs = np.fft.fftfreq(N, 1/sr)[:N//2]
    fig, ax = plt.subplots(figsize=(14, 4))
    ax.set_title(titulo, fontsize=16)
    ax.plot(freqs, fft, color='blue')
    ax.set_xlabel("Frequ√™ncia (Hz)", fontsize=14)
    ax.set_ylabel("Amplitude", fontsize=14)
    ax.grid(True)
    ax.tick_params(axis='both', which='major', labelsize=12)
    st.pyplot(fig)
    plt.close(fig)

def plot_espectrograma(data, sr, titulo="Espectrograma (STFT)"):
    """
    Plota o espectrograma (STFT) do √°udio.

    Parameters:
    - data (np.ndarray): Sinal de √°udio.
    - sr (int): Taxa de amostragem.
    - titulo (str): T√≠tulo do gr√°fico.
    """
    D = np.abs(librosa.stft(data))
    DB = librosa.amplitude_to_db(D, ref=np.max)
    fig, ax = plt.subplots(figsize=(14, 4))
    ax.set_title(titulo, fontsize=16)
    
    # Usar 'time' e 'hz' para evitar erros
    mappable = ld.specshow(DB, sr=sr, x_axis='time', y_axis='hz', cmap='magma', ax=ax)
    
    cbar = plt.colorbar(mappable=mappable, ax=ax, format='%+2.0f dB')
    cbar.ax.set_ylabel("Intensidade (dB)", fontsize=14)
    
    # Personalizar r√≥tulos dos eixos
    ax.set_xlabel("Tempo (segundos)", fontsize=14)
    ax.set_ylabel("Frequ√™ncia (Hz)", fontsize=14)
    
    ax.tick_params(axis='both', which='major', labelsize=12)
    st.pyplot(fig)
    plt.close(fig)
    
    # Adicionar explica√ß√£o para o usu√°rio
    with st.expander("üìñ Entenda o Espectrograma (STFT)"):
        st.markdown("""
        ### O que √© um Espectrograma (STFT)?
        
        Um **Espectrograma** √© uma representa√ß√£o visual do espectro de frequ√™ncias de um sinal ao longo do tempo. Ele mostra como as frequ√™ncias presentes no √°udio mudam √† medida que o tempo passa.

        - **Eixo X (Tempo):** Representa o tempo em segundos.
        - **Eixo Y (Frequ√™ncia):** Representa a frequ√™ncia em Hertz (Hz).
        - **Cores:** Indicam a intensidade (ou amplitude) das frequ√™ncias. Cores mais claras representam frequ√™ncias mais intensas.
        
        **Exemplo Visual:**
        ![Espectrograma](https://commons.wikimedia.org/wiki/File:Spectrogram-19thC.png#/media/File:Spectrogram-19thC.png)
        """)

def plot_mfcc(data, sr, titulo="Espectrograma (MFCC)"):
    """
    Plota o espectrograma de MFCC do √°udio.

    Parameters:
    - data (np.ndarray): Sinal de √°udio.
    - sr (int): Taxa de amostragem.
    - titulo (str): T√≠tulo do gr√°fico.
    """
    mfccs = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40)
    mfccs_db = librosa.amplitude_to_db(np.abs(mfccs))
    fig, ax = plt.subplots(figsize=(14, 4))
    ax.set_title(titulo, fontsize=16)
    
    # Usar 'time' e 'mel' para evitar erros
    mappable = ld.specshow(mfccs_db, x_axis='time', y_axis='mel', cmap='Spectral', sr=sr, ax=ax)
    
    cbar = plt.colorbar(mappable=mappable, ax=ax, format='%+2.f dB')
    cbar.ax.set_ylabel("Intensidade (dB)", fontsize=14)
    
    # Personalizar r√≥tulos dos eixos
    ax.set_xlabel("Tempo (segundos)", fontsize=14)
    ax.set_ylabel("Frequ√™ncia (Mel)", fontsize=14)
    
    ax.tick_params(axis='both', which='major', labelsize=12)
    st.pyplot(fig)
    plt.close(fig)
    
    # Adicionar explica√ß√£o para o usu√°rio
    with st.expander("üìñ Entenda o Espectrograma de MFCC"):
        st.markdown("""
        ### O que s√£o MFCCs?

        **MFCCs (Mel-Frequency Cepstral Coefficients)** s√£o caracter√≠sticas extra√≠das do √°udio que representam a pot√™ncia espectral em diferentes frequ√™ncias na escala Mel, que √© mais alinhada com a percep√ß√£o humana de som.

        - **Eixo X (Tempo):** Representa o tempo em segundos.
        - **Eixo Y (Frequ√™ncia Mel):** Representa a frequ√™ncia na escala Mel.
        - **Cores:** Indicam a intensidade das frequ√™ncias. Cores mais claras representam frequ√™ncias mais intensas.
        
        **Por que usar MFCCs?**
        MFCCs s√£o amplamente utilizados em reconhecimento de fala e classifica√ß√£o de √°udio porque capturam as caracter√≠sticas essenciais do som de forma compacta e eficaz.
        
        **Exemplo Visual:**
        ![Espectrograma de MFCC](https://upload.wikimedia.org/wikipedia/commons/1/1c/Spectrogram_of_white_noise.svg)
        """)

def plot_probabilidades_classes(class_probs, titulo="Probabilidades das Classes"):
    """
    Plota as probabilidades das classes em um gr√°fico de barras.

    Parameters:
    - class_probs (dict): Dicion√°rio com as probabilidades de cada classe.
    - titulo (str): T√≠tulo do gr√°fico.
    """
    classes = list(class_probs.keys())
    probs = list(class_probs.values())

    fig, ax = plt.subplots(figsize=(12, 6))
    sns.barplot(x=classes, y=probs, palette='viridis', ax=ax)
    ax.set_title(titulo, fontsize=16)
    ax.set_xlabel("Classes", fontsize=14)
    ax.set_ylabel("Probabilidade", fontsize=14)
    ax.set_ylim(0, 1)  # Probabilidades entre 0 e 1
    ax.tick_params(axis='both', which='major', labelsize=12)
    
    # Adiciona r√≥tulos de porcentagem acima das barras
    for i, v in enumerate(probs):
        ax.text(i, v + 0.01, f"{v*100:.2f}%", ha='center', va='bottom', fontsize=12)
    
    # Corre√ß√£o do aviso de deprecia√ß√£o do Seaborn
    # Adicionando 'hue' e removendo a legenda
    sns.barplot(x=classes, y=probs, hue=classes, palette='viridis', ax=ax, legend=False)
    
    st.pyplot(fig)
    plt.close(fig)

def processar_novo_audio(caminho_audio, modelo, labelencoder):
    """
    Carrega, extrai features e classifica um novo arquivo de √°udio.

    Parameters:
    - caminho_audio (str): Caminho para o arquivo de √°udio.
    - modelo (tf.keras.Model ou torch.nn.Module): Modelo treinado para classifica√ß√£o.
    - labelencoder (LabelEncoder): Codificador de labels para decodificar classes.

    Returns:
    - pred_label (str): R√≥tulo da classe prevista.
    - confidence (float): Grau de confian√ßa da previs√£o.
    - class_probs (dict): Dicion√°rio com as probabilidades de cada classe.
    """
    # Carrega o √°udio
    data, sr = carregar_audio(caminho_audio, sr=None)

    if data is None:
        return None, None, None

    # Extrai as features (MFCCs)
    mfccs = extrair_features(data, sr)

    if mfccs is None:
        return None, None, None

    # Ajusta o shape dos MFCCs para compatibilidade com o modelo
    # Conv1D espera dados com forma (samples, timesteps, features)
    # Aqui, timesteps correspondem ao n√∫mero de features (MFCCs) e features=1
    mfccs = mfccs.reshape(1, -1, 1)  # Forma: (1, n_features, 1)

    # Realiza a predi√ß√£o usando o modelo treinado
    if isinstance(modelo, tf.keras.Model):
        prediction = modelo.predict(mfccs)
    elif isinstance(modelo, torch.nn.Module):
        modelo.eval()
        with torch.no_grad():
            mfccs_tensor = torch.tensor(mfccs, dtype=torch.float32)
            prediction = modelo(mfccs_tensor).numpy()
    else:
        st.error("Modelo n√£o suportado.")
        return None, None, None

    # Obt√©m a classe com a maior probabilidade
    pred_class = np.argmax(prediction, axis=1)

    # Obt√©m o r√≥tulo da classe prevista
    pred_label = labelencoder.inverse_transform(pred_class)

    # Obt√©m a confian√ßa da predi√ß√£o
    confidence = prediction[0][pred_class][0]

    # Cria um dicion√°rio com as probabilidades de cada classe
    class_probs = {labelencoder.classes_[i]: float(prediction[0][i]) for i in range(len(labelencoder.classes_))}

    return pred_label[0], confidence, class_probs

# ==================== CONFIGURA√á√ÉO DA APLICA√á√ÉO STREAMLIT ====================

def classificar_audio(SEED):
    st.header("Classifica√ß√£o de Novo √Åudio")

    st.write("### Passo 1: Carregar o Modelo Treinado")
    st.write("**Formatos Aceitos:** `.keras`, `.h5` para modelos Keras ou `.pth` para modelos PyTorch.")
    modelo_file = st.file_uploader(
        "Fa√ßa upload do arquivo do modelo", 
        type=["keras", "h5", "pth"], 
        key="model_upload"
    )

    if modelo_file is not None:
        try:
            st.write(f"**Modelo Carregado:** {modelo_file.name}")
            # Salva o modelo temporariamente
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(modelo_file.name)[1]) as tmp_model:
                tmp_model.write(modelo_file.read())
                caminho_modelo = tmp_model.name

            # Carrega o modelo
            if caminho_modelo.endswith('.pth'):
                # Para modelos PyTorch, carregue de forma apropriada
                modelo = torch.load(caminho_modelo, map_location=torch.device('cpu'))
                modelo.eval()
                st.write("**Tipo de Modelo:** PyTorch")
            elif caminho_modelo.endswith(('.h5', '.keras')):
                # Para modelos Keras (.h5 e .keras)
                modelo = load_model(caminho_modelo, compile=False)
                st.write("**Tipo de Modelo:** Keras")
            else:
                st.error("Formato de modelo n√£o suportado. Utilize .keras, .h5 ou .pth.")
                return
            st.success("Modelo carregado com sucesso!")

            # Carrega as classes
            st.write("### Passo 2: Carregar o Arquivo de Classes")
            st.write("**Formato Aceito:** `.txt`")
            classes_file = st.file_uploader(
                "Fa√ßa upload do arquivo com as classes (classes.txt)", 
                type=["txt"], 
                key="classes_upload"
            )
            if classes_file is not None:
                classes = classes_file.read().decode("utf-8").splitlines()
                labelencoder = LabelEncoder()
                labelencoder.fit(classes)
                st.success("Classes carregadas com sucesso!")
                st.write(f"**Classes:** {', '.join(classes)}")

                st.write("### Passo 3: Upload do Arquivo de √Åudio para Classifica√ß√£o")
                audio_upload = st.file_uploader(
                    "Fa√ßa upload de um arquivo de √°udio (.wav, .mp3, .flac, .ogg ou .m4a)", 
                    type=["wav", "mp3", "flac", "ogg", "m4a"], 
                    key="audio_upload"
                )

                if audio_upload is not None:
                    # Salva o arquivo de √°udio temporariamente
                    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(audio_upload.name)[1]) as tmp_audio:
                        tmp_audio.write(audio_upload.read())
                        caminho_audio = tmp_audio.name

                    # Exibe o √°udio
                    st.audio(caminho_audio, format=f'audio/{os.path.splitext(audio_upload.name)[1][1:]}')

                    # Realiza a classifica√ß√£o
                    with st.spinner('Classificando...'):
                        rotulo_predito, confianca, probs_classes = processar_novo_audio(caminho_audio, modelo, labelencoder)

                    if rotulo_predito is not None and confianca is not None:
                        st.success(f"**Classe Predita:** {rotulo_predito}")
                        st.info(f"**Grau de Confian√ßa:** {confianca * 100:.2f}%")

                        st.write("### Probabilidades das Classes:")
                        plot_probabilidades_classes(probs_classes, titulo="Probabilidades das Classes")

                        # Visualiza√ß√µes
                        st.write("### Visualiza√ß√µes do √Åudio:")
                        data, sr = carregar_audio(caminho_audio, sr=None)
                        if data is not None:
                            plot_forma_onda(data, sr, titulo=f"Forma de Onda - {rotulo_predito}")
                            plot_espectro_frequencias(data, sr, titulo=f"Espectro de Frequ√™ncias - {rotulo_predito}")
                            plot_espectrograma(data, sr, titulo=f"Espectrograma STFT - {rotulo_predito}")
                            plot_mfcc(data, sr, titulo=f"Espectrograma MFCC - {rotulo_predito}")
                    else:
                        st.error("A classifica√ß√£o n√£o p√¥de ser realizada devido a erros no processamento do √°udio.")

                    # Remove os arquivos tempor√°rios
                    os.remove(caminho_audio)
        except Exception as e:
            st.error(f"Erro ao carregar o modelo: {e}")
            # Assegura a remo√ß√£o do arquivo tempor√°rio do modelo em caso de erro
            if 'caminho_modelo' in locals() and os.path.exists(caminho_modelo):
                os.remove(caminho_modelo)

def treinar_modelo(SEED):
    st.header("Treinamento do Modelo CNN")

    st.write("""
    ### Passo 1: Upload do Dataset
    O **dataset** deve estar organizado em um arquivo ZIP com pastas para cada classe. Por exemplo:
    ```
    dataset.zip/
    ‚îú‚îÄ‚îÄ agua_gelada/
    ‚îÇ   ‚îú‚îÄ‚îÄ arquivo1.wav
    ‚îÇ   ‚îú‚îÄ‚îÄ arquivo2.wav
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îú‚îÄ‚îÄ agua_quente/
    ‚îÇ   ‚îú‚îÄ‚îÄ arquivo1.wav
    ‚îÇ   ‚îú‚îÄ‚îÄ arquivo2.wav
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ ...
    ```
    """)

    zip_upload = st.file_uploader(
        "Fa√ßa upload do arquivo ZIP contendo as pastas das classes", 
        type=["zip"], 
        key="dataset_upload"
    )

    if zip_upload is not None:
        try:
            st.write("#### Extraindo o Dataset...")
            # Salva o arquivo ZIP temporariamente
            with tempfile.NamedTemporaryFile(delete=False, suffix=".zip") as tmp_zip:
                tmp_zip.write(zip_upload.read())
                caminho_zip = tmp_zip.name

            # Extrai o ZIP
            diretorio_extracao = tempfile.mkdtemp()
            with zipfile.ZipFile(caminho_zip, 'r') as zip_ref:
                zip_ref.extractall(diretorio_extracao)
            caminho_base = diretorio_extracao

            # Verifica se h√° subpastas (classes)
            categorias = [d for d in os.listdir(caminho_base) if os.path.isdir(os.path.join(caminho_base, d))]

            if len(categorias) == 0:
                st.error("Nenhuma subpasta de classes encontrada no ZIP. Verifique a estrutura do seu arquivo ZIP.")
                return

            st.success("Dataset extra√≠do com sucesso!")
            st.write(f"**Classes encontradas:** {', '.join(categorias)}")

            # Coleta os caminhos dos arquivos e labels
            caminhos_arquivos = []
            labels = []
            for cat in categorias:
                caminho_cat = os.path.join(caminho_base, cat)
                arquivos_na_cat = [f for f in os.listdir(caminho_cat) if f.lower().endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a'))]
                st.write(f"**Classe '{cat}':** {len(arquivos_na_cat)} arquivos encontrados.")
                if len(arquivos_na_cat) == 0:
                    st.warning(f"Nenhum arquivo encontrado na classe '{cat}'.")
                for nome_arquivo in arquivos_na_cat:
                    caminho_completo = os.path.join(caminho_cat, nome_arquivo)
                    caminhos_arquivos.append(caminho_completo)
                    labels.append(cat)

            df = pd.DataFrame({'caminho_arquivo': caminhos_arquivos, 'classe': labels})
            st.write("### Primeiras Amostras do Dataset:")
            st.dataframe(df.head())

            if len(df) == 0:
                st.error("Nenhuma amostra encontrada no dataset. Verifique os arquivos de √°udio.")
                return

            # Codifica√ß√£o das classes
            labelencoder = LabelEncoder()
            y = labelencoder.fit_transform(df['classe'])
            classes = labelencoder.classes_
            st.write(f"**Classes codificadas:** {', '.join(classes)}")

            # **Explica√ß√£o dos Dados**
            with st.expander("üìñ Explica√ß√£o dos Dados"):
                st.markdown("""
                ### Explica√ß√£o dos Dados

                **1. Features Extra√≠das: (10, 40)**
                - **O que s√£o Features?**
                  Features s√£o caracter√≠sticas ou informa√ß√µes espec√≠ficas extra√≠das dos dados brutos (neste caso, arquivos de √°udio) que s√£o usadas para treinar o modelo.
                - **Interpreta√ß√£o de (10, 40):**
                  - **10:** N√∫mero de amostras ou exemplos no conjunto de dados.
                  - **40:** N√∫mero de caracter√≠sticas extra√≠das de cada amostra.
                - **Explica√ß√£o Simples:**
                  Imagine que voc√™ tem 10 arquivos de √°udio diferentes. Para cada um deles, extra√≠mos 40 caracter√≠sticas que ajudam o modelo a entender e diferenciar os sons.

                **2. Divis√£o dos Dados:**
                Ap√≥s extrair as features, os dados s√£o divididos em diferentes conjuntos para treinar e avaliar o modelo.

                - **Treino: (8, 40)**
                  - **8:** N√∫mero de amostras usadas para treinar o modelo.
                  - **40:** N√∫mero de caracter√≠sticas por amostra.
                  - **Explica√ß√£o:** Das 10 amostras iniciais, 8 s√£o usadas para ensinar o modelo a reconhecer os padr√µes.

                - **Teste: (2, 40)**
                  - **2:** N√∫mero de amostras usadas para testar a performance do modelo.
                  - **40:** N√∫mero de caracter√≠sticas por amostra.
                  - **Explica√ß√£o:** As 2 amostras restantes s√£o usadas para verificar se o modelo aprendeu corretamente.

                **Dados Aumentados: (80, 40)**
                - **80:** N√∫mero de amostras adicionais geradas atrav√©s de t√©cnicas de aumento de dados.
                - **40:** N√∫mero de caracter√≠sticas por amostra.
                - **Explica√ß√£o:** Para melhorar a performance do modelo, criamos 80 novas amostras a partir das originais, aplicando transforma√ß√µes como adicionar ru√≠do ou alterar o pitch.
                """)

            # **Exibir N√∫mero de Classes e Distribui√ß√£o**
            st.write(f"### N√∫mero de Classes: {len(classes)}")
            contagem_classes = df['classe'].value_counts()
            st.write("### Distribui√ß√£o das Classes:")
            fig_dist, ax_dist = plt.subplots(figsize=(10, 6))
            # Corre√ß√£o do aviso do Seaborn adicionando 'hue' e removendo a legenda
            sns.barplot(x=contagem_classes.index, y=contagem_classes.values, hue=contagem_classes.index, palette='viridis', ax=ax_dist, legend=False)
            ax_dist.set_xlabel("Classes", fontsize=14)
            ax_dist.set_ylabel("N√∫mero de Amostras", fontsize=14)
            ax_dist.set_title("Distribui√ß√£o das Classes no Dataset", fontsize=16)
            ax_dist.tick_params(axis='both', which='major', labelsize=12)
            st.pyplot(fig_dist)
            plt.close(fig_dist)

            # ==================== COLUNA DE CONFIGURA√á√ÉO ====================
            st.sidebar.header("Configura√ß√µes de Treinamento")

            # N√∫mero de √âpocas
            num_epochs = st.sidebar.slider(
                "N√∫mero de √âpocas:",
                min_value=10,
                max_value=500,
                value=200,
                step=10,
                help="Define quantas vezes o modelo percorrer√° todo o conjunto de dados durante o treinamento."
            )

            # Tamanho do Batch
            batch_size = st.sidebar.selectbox(
                "Tamanho do Batch:",
                options=[8, 16, 32, 64, 128],
                index=0,  # Seleciona 8 como padr√£o
                help="N√∫mero de amostras processadas antes de atualizar os pesos do modelo. M√≠nimo de 8."
            )

            # Fator de Aumento de Dados
            augment_factor = st.sidebar.slider(
                "Fator de Aumento de Dados:",
                min_value=1,
                max_value=20,
                value=10,
                step=1,
                help="Define quantas amostras aumentadas ser√£o geradas a partir de cada amostra original."
            )

            # Taxa de Dropout
            dropout_rate = st.sidebar.slider(
                "Taxa de Dropout:",
                min_value=0.0,
                max_value=0.9,
                value=0.4,
                step=0.05,
                help="Propor√ß√£o de neur√¥nios a serem desligados durante o treinamento para evitar overfitting."
            )

            # Ativar/Desativar Data Augmentation
            enable_augmentation = st.sidebar.checkbox(
                "Ativar Data Augmentation",
                value=True,
                help="Permite ao usu√°rio escolher se deseja ou n√£o aplicar t√©cnicas de aumento de dados."
            )

            # Sele√ß√£o de Tipos de Data Augmentation
            if enable_augmentation:
                st.sidebar.subheader("Tipos de Data Augmentation")
                adicionar_ruido = st.sidebar.checkbox(
                    "Adicionar Ru√≠do Gaussiano",
                    value=True,
                    help="Adiciona ru√≠do gaussiano ao √°udio para simular varia√ß√µes de som."
                )
                estiramento_tempo = st.sidebar.checkbox(
                    "Estiramento de Tempo",
                    value=True,
                    help="Altera a velocidade do √°udio sem alterar seu tom."
                )
                alteracao_pitch = st.sidebar.checkbox(
                    "Altera√ß√£o de Pitch",
                    value=True,
                    help="Altera o tom do √°udio sem alterar sua velocidade."
                )
                deslocamento = st.sidebar.checkbox(
                    "Deslocamento",
                    value=True,
                    help="Desloca o √°udio no tempo, adicionando sil√™ncio no in√≠cio ou no final."
                )

            # Balanceamento Ponderado das Classes
            st.sidebar.subheader("Balanceamento das Classes")
            balance_classes = st.sidebar.selectbox(
                "M√©todo de Balanceamento das Classes:",
                options=["Balanced", "None"],
                index=0,
                help="Escolha 'Balanced' para aplicar balanceamento ponderado das classes ou 'None' para n√£o aplicar."
            )
            # ==================== FIM DA COLUNA DE CONFIGURA√á√ÉO ====================

            # Extra√ß√£o de Features
            st.write("### Extraindo Features (MFCCs)...")
            st.write("""
            **MFCCs (Mel-Frequency Cepstral Coefficients)** s√£o caracter√≠sticas extra√≠das do √°udio que representam a pot√™ncia espectral em diferentes frequ√™ncias. Eles s√£o amplamente utilizados em processamento de √°udio e reconhecimento de padr√µes, pois capturam informa√ß√µes relevantes para identificar sons distintos.
            """)
            X = []
            y_valid = []

            for i, row in df.iterrows():
                arquivo = row['caminho_arquivo']
                data, sr = carregar_audio(arquivo, sr=None)
                if data is not None:
                    features = extrair_features(data, sr)
                    if features is not None:
                        X.append(features)
                        y_valid.append(y[i])
                    else:
                        st.warning(f"Erro na extra√ß√£o de features do arquivo '{arquivo}'.")
                else:
                    st.warning(f"Erro no carregamento do arquivo '{arquivo}'.")

            X = np.array(X)
            y_valid = np.array(y_valid)

            st.write(f"**Features extra√≠das:** {X.shape}")

            # **Explica√ß√£o das Features Extra√≠das**
            with st.expander("üìñ Explica√ß√£o das Features Extra√≠das"):
                st.markdown("""
                **1. Features Extra√≠das: (10, 40)**
                - **O que s√£o Features?**
                  Features s√£o caracter√≠sticas ou informa√ß√µes espec√≠ficas extra√≠das dos dados brutos (neste caso, arquivos de √°udio) que s√£o usadas para treinar o modelo.
                - **Interpreta√ß√£o de (10, 40):**
                  - **10:** N√∫mero de amostras ou exemplos no conjunto de dados.
                  - **40:** N√∫mero de caracter√≠sticas extra√≠das de cada amostra.
                - **Explica√ß√£o Simples:**
                  Imagine que voc√™ tem 10 arquivos de √°udio diferentes. Para cada um deles, extra√≠mos 40 caracter√≠sticas que ajudam o modelo a entender e diferenciar os sons.
                """)

            # Divis√£o dos Dados
            st.write("### Dividindo os Dados em Treino e Teste...")
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y_valid, test_size=0.2, random_state=SEED, stratify=y_valid)
            st.write(f"**Treino:** {X_train.shape}, **Teste:** {X_test.shape}")

            # **Explica√ß√£o da Divis√£o dos Dados**
            with st.expander("üìñ Explica√ß√£o da Divis√£o dos Dados"):
                st.markdown("""
                **2. Divis√£o dos Dados:**
                Ap√≥s extrair as features, os dados s√£o divididos em diferentes conjuntos para treinar e avaliar o modelo.

                - **Treino: (8, 40)**
                  - **8:** N√∫mero de amostras usadas para treinar o modelo.
                  - **40:** N√∫mero de caracter√≠sticas por amostra.
                  - **Explica√ß√£o:** Das 10 amostras iniciais, 8 s√£o usadas para ensinar o modelo a reconhecer os padr√µes.

                - **Teste: (2, 40)**
                  - **2:** N√∫mero de amostras usadas para testar a performance do modelo.
                  - **40:** N√∫mero de caracter√≠sticas por amostra.
                  - **Explica√ß√£o:** As 2 amostras restantes s√£o usadas para verificar se o modelo aprendeu corretamente.
                """)

            # Data Augmentation no Treino
            if enable_augmentation:
                st.write("### Aplicando Data Augmentation no Conjunto de Treino...")
                st.write("""
                **Data Augmentation** √© uma t√©cnica utilizada para aumentar a quantidade e diversidade dos dados de treinamento aplicando transforma√ß√µes nos dados originais. Isso ajuda o modelo a generalizar melhor e reduzir o overfitting.
                """)
                X_train_augmented = []
                y_train_augmented = []

                for i in range(len(X_train)):
                    arquivo = df['caminho_arquivo'].iloc[i]
                    data, sr = carregar_audio(arquivo, sr=None)
                    if data is not None:
                        for _ in range(augment_factor):
                            # Aplicar apenas as transforma√ß√µes selecionadas
                            transformacoes = []
                            if adicionar_ruido:
                                transformacoes.append(AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=1.0))
                            if estiramento_tempo:
                                transformacoes.append(TimeStretch(min_rate=0.8, max_rate=1.25, p=1.0))
                            if alteracao_pitch:
                                transformacoes.append(PitchShift(min_semitones=-4, max_semitones=4, p=1.0))
                            if deslocamento:
                                transformacoes.append(Shift(min_shift=-0.5, max_shift=0.5, p=1.0))

                            if transformacoes:
                                augmentations = Compose(transformacoes)
                                augmented_data = aumentar_audio(data, sr, augmentations)

                                features = extrair_features(augmented_data, sr)
                                if features is not None:
                                    X_train_augmented.append(features)
                                    y_train_augmented.append(y_train[i])
                                else:
                                    st.warning(f"Erro na extra√ß√£o de features de uma amostra aumentada do arquivo '{arquivo}'.")
                    else:
                        st.warning(f"Erro no carregamento do arquivo '{arquivo}' para Data Augmentation.")

                X_train_augmented = np.array(X_train_augmented)
                y_train_augmented = np.array(y_train_augmented)
                st.write(f"**Dados aumentados:** {X_train_augmented.shape}")

                # **Explica√ß√£o dos Dados Aumentados**
                with st.expander("üìñ Explica√ß√£o dos Dados Aumentados"):
                    st.markdown("""
                    **Dados Aumentados: (80, 40)**
                    - **80:** N√∫mero de amostras adicionais geradas atrav√©s de t√©cnicas de aumento de dados.
                    - **40:** N√∫mero de caracter√≠sticas por amostra.
                    - **Explica√ß√£o:** Para melhorar a performance do modelo, criamos 80 novas amostras a partir das originais, aplicando transforma√ß√µes como adicionar ru√≠do ou alterar o pitch.
                    """)

                # Combina√ß√£o dos Dados
                X_train_combined = np.concatenate((X_train, X_train_augmented), axis=0)
                y_train_combined = np.concatenate((y_train, y_train_augmented), axis=0)
                st.write(f"**Treino combinado:** {X_train_combined.shape}")

                # **Explica√ß√£o da Combina√ß√£o dos Dados**
                with st.expander("üìñ Explica√ß√£o da Combina√ß√£o dos Dados"):
                    st.markdown("""
                    **3. Combina√ß√£o e Valida√ß√£o:**
                    - **Treino Combinado: (88, 40)**
                      - **88:** Soma das amostras de treino original (8) e aumentadas (80).
                      - **40:** N√∫mero de caracter√≠sticas por amostra.
                      - **Explica√ß√£o:** Unimos as amostras originais com as aumentadas para formar um conjunto de treino mais robusto.
                    """)

            else:
                X_train_combined = X_train
                y_train_combined = y_train

            # Divis√£o em Treino Final e Valida√ß√£o
            st.write("### Dividindo o Treino Combinado em Treino Final e Valida√ß√£o...")
            X_train_final, X_val, y_train_final, y_val = train_test_split(
                X_train_combined, y_train_combined, test_size=0.1, random_state=SEED, stratify=y_train_combined)
            st.write(f"**Treino Final:** {X_train_final.shape}, **Valida√ß√£o:** {X_val.shape}")

            # **Explica√ß√£o da Divis√£o Final**
            with st.expander("üìñ Explica√ß√£o da Combina√ß√£o e Valida√ß√£o"):
                st.markdown("""
                **3. Combina√ß√£o e Valida√ß√£o:**
                - **Treino Combinado: (88, 40)**
                  - **88:** Soma das amostras de treino original (8) e aumentadas (80).
                  - **40:** N√∫mero de caracter√≠sticas por amostra.
                  - **Explica√ß√£o:** Unimos as amostras originais com as aumentadas para formar um conjunto de treino mais robusto.
                - **Treino Final: (79, 40)**
                  - **79:** N√∫mero de amostras ap√≥s uma divis√£o adicional para valida√ß√£o.
                  - **40:** N√∫mero de caracter√≠sticas por amostra.
                  - **Explica√ß√£o:** Das 88 amostras combinadas, 79 s√£o usadas para treinar o modelo definitivamente.
                - **Valida√ß√£o: (9, 40)**
                  - **9:** N√∫mero de amostras usadas para validar o modelo durante o treinamento.
                  - **40:** N√∫mero de caracter√≠sticas por amostra.
                  - **Explica√ß√£o:** As 9 amostras restantes s√£o usadas para monitorar se o modelo est√° aprendendo de forma adequada.
                """)

            # Ajuste da Forma dos Dados para a CNN (Conv1D)
            st.write("### Ajustando a Forma dos Dados para a CNN (Conv1D)...")
            X_train_final = X_train_final.reshape((X_train_final.shape[0], X_train_final.shape[1], 1))
            X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))
            X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
            st.write(f"**Shapes:** Treino Final: {X_train_final.shape}, Valida√ß√£o: {X_val.shape}, Teste: {X_test.shape}")

            # **Explica√ß√£o do Ajuste das Shapes**
            with st.expander("üìñ Explica√ß√£o do Ajuste das Shapes"):
                st.markdown("""
                **4. Ajuste das Shapes para a CNN:**
                Ap√≥s a prepara√ß√£o dos dados, √© necess√°rio ajustar a shape (dimens√µes) dos dados para que sejam compat√≠veis com a Rede Neural Convolucional (CNN).

                - **Treino Final: (79, 40, 1)**
                - **Valida√ß√£o: (9, 40, 1)**
                - **Teste: (2, 40, 1)**
                
                - **Interpreta√ß√£o:**
                  - **79, 9, 2:** N√∫mero de amostras nos conjuntos de treino final, valida√ß√£o e teste, respectivamente.
                  - **40:** N√∫mero de caracter√≠sticas (features) por amostra.
                  - **1:** N√∫mero de canais. Neste caso, temos um √∫nico canal, pois estamos lidando com dados unidimensionais (√°udio).

                - **Explica√ß√£o Simples:**
                  Cada amostra de √°udio agora tem uma dimens√£o extra (1) para indicar que h√° apenas um canal de informa√ß√£o, o que √© necess√°rio para processar os dados na CNN.
                """)

            # C√°lculo de Class Weights
            st.write("### Calculando Class Weights para Balanceamento das Classes...")
            st.write("""
            **Class Weights** s√£o utilizados para lidar com desequil√≠brios nas classes do conjunto de dados. Quando algumas classes t√™m muito mais amostras do que outras, o modelo pode se tornar tendencioso em favor das classes mais frequentes. Aplicar pesos balanceados ajuda o modelo a prestar mais aten√ß√£o √†s classes menos representadas.
            """)
            from sklearn.utils.class_weight import compute_class_weight
            if balance_classes == "Balanced":
                class_weights = compute_class_weight(
                    class_weight='balanced',
                    classes=np.unique(y_train_final),
                    y=y_train_final
                )
                class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}
                st.write(f"**Pesos das Classes:** {class_weight_dict}")
            else:
                class_weight_dict = None
                st.write("**Balanceamento de classes n√£o aplicado.**")

            # Defini√ß√£o da Arquitetura da CNN
            st.write("### Definindo a Arquitetura da Rede Neural Convolucional (CNN)...")
            st.write("""
            A **Rede Neural Convolucional (CNN)** √© uma arquitetura de rede neural eficaz para processamento de dados com estrutura de grade, como imagens e sinais de √°udio. Nesta aplica√ß√£o, utilizamos camadas convolucionais para extrair caracter√≠sticas relevantes dos dados de √°udio.
            """)

            from tensorflow.keras.models import Sequential
            from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input

            modelo = Sequential([
                Input(shape=(X_train_final.shape[1], 1)),
                Conv1D(64, kernel_size=10, activation='relu'),
                Dropout(dropout_rate),
                MaxPooling1D(pool_size=4),
                Conv1D(128, kernel_size=10, activation='relu', padding='same'),
                Dropout(dropout_rate),
                MaxPooling1D(pool_size=4),
                Flatten(),
                Dense(64, activation='relu'),
                Dropout(dropout_rate),
                Dense(len(classes), activation='softmax')
            ])

            # Compila√ß√£o do Modelo
            modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

            # **Exibi√ß√£o do Resumo do Modelo como Tabela**
            st.write("### Resumo do Modelo:")
            st.write("""
            A tabela abaixo apresenta as camadas da rede neural, a forma de sa√≠da de cada camada e o n√∫mero de par√¢metros (pesos) que cada camada possui. 
            - **Camada (Tipo):** Nome e tipo da camada.
            - **Forma de Sa√≠da:** Dimens√µes da sa√≠da da camada.
            - **Par√¢metros:** N√∫mero de par√¢metros trein√°veis na camada.
            """)

            resumo_modelo = []
            for layer in modelo.layers:
                nome_layer = layer.name
                tipo_layer = layer.__class__.__name__
                try:
                    forma_saida = layer.output_shape
                except AttributeError:
                    forma_saida = 'N/A'
                parametros = layer.count_params()
                resumo_modelo.append({
                    'Camada (Tipo)': f"{nome_layer} ({tipo_layer})",
                    'Forma de Sa√≠da': forma_saida,
                    'Par√¢metros': f"{parametros:,}"
                })

            # Cria√ß√£o do DataFrame
            df_resumo = pd.DataFrame(resumo_modelo)

            # Adicionar total de par√¢metros
            total_parametros = modelo.count_params()
            parametros_trainable = np.sum([layer.count_params() for layer in modelo.layers if layer.trainable])
            parametros_nao_trainable = total_parametros - parametros_trainable

            # Exibi√ß√£o da tabela
            st.dataframe(df_resumo)

            # Exibi√ß√£o dos totais
            st.write(f"**Total de par√¢metros:** {total_parametros:,} ({total_parametros / 1e3:.2f} KB)")
            st.write(f"**Par√¢metros trein√°veis:** {parametros_trainable:,} ({parametros_trainable / 1e3:.2f} KB)")
            st.write(f"**Par√¢metros n√£o trein√°veis:** {parametros_nao_trainable:,} ({parametros_nao_trainable / 1e3:.2f} KB)")

            # **Explica√ß√£o das Camadas do Modelo**
            with st.expander("üìñ Explica√ß√£o das Camadas do Modelo"):
                st.markdown("""
                ### Explica√ß√£o das Camadas do Modelo

                As camadas de uma Rede Neural Convolucional (CNN) s√£o respons√°veis por processar e aprender padr√µes nos dados. Vamos explicar cada uma das camadas presentes no seu modelo de forma simples:

                **1. Conv1D (Conv1D)**
                - **O que √©?**
                  Conv1D √© uma camada convolucional unidimensional usada para processar dados sequenciais, como √°udio ou s√©ries temporais.
                - **Fun√ß√£o:**
                  **Extrair Padr√µes Locais:** Ela passa uma janela (filtro) sobre os dados para detectar padr√µes espec√≠ficos, como certas frequ√™ncias ou ritmos no √°udio.
                - **Exemplo no Modelo:**
                  ```python
                  Conv1D(64, kernel_size=10, activation='relu')
                  ```
                  - **64:** N√∫mero de filtros (detetores de padr√µes) usados.
                  - **kernel_size=10:** Tamanho da janela que percorre os dados.
                  - **activation='relu':** Fun√ß√£o de ativa√ß√£o que introduz n√£o-linearidade.

                **2. Dropout (Dropout)**
                - **O que √©?**
                  Dropout √© uma t√©cnica de regulariza√ß√£o que ajuda a prevenir o overfitting.
                - **Fun√ß√£o:**
                  **Desligar Neur√¥nios Aleatoriamente:** Durante o treinamento, desliga aleatoriamente uma porcentagem dos neur√¥nios, for√ßando o modelo a n√£o depender excessivamente de nenhum neur√¥nio espec√≠fico.
                - **Exemplo no Modelo:**
                  ```python
                  Dropout(0.4)
                  ```
                  - **0.4:** 40% dos neur√¥nios ser√£o desligados durante o treinamento.

                **3. MaxPooling1D (MaxPooling1D)**
                - **O que √©?**
                  MaxPooling1D √© uma camada de pooling que reduz a dimensionalidade dos dados.
                - **Fun√ß√£o:**
                  **Reduzir a Dimensionalidade:** Seleciona o valor m√°ximo em cada janela de tamanho especificado, resumindo a informa√ß√£o e reduzindo o n√∫mero de par√¢metros.
                - **Exemplo no Modelo:**
                  ```python
                  MaxPooling1D(pool_size=4)
                  ```
                  - **pool_size=4:** Seleciona o maior valor em janelas de 4 unidades.

                **4. Conv1D_1 (Conv1D)**
                - **O que √©?**
                  Outra camada convolucional para extrair padr√µes mais complexos dos dados.
                - **Fun√ß√£o:**
                  Similar √† primeira camada Conv1D, mas com mais filtros para capturar padr√µes mais elaborados.
                - **Exemplo no Modelo:**
                  ```python
                  Conv1D(128, kernel_size=10, activation='relu', padding='same')
                  ```
                  - **128:** N√∫mero de filtros.
                  - **kernel_size=10:** Tamanho da janela.
                  - **padding='same':** Mant√©m as dimens√µes dos dados.

                **5. Dropout_1 (Dropout)**
                - **O que √©?**
                  Segunda camada de dropout para refor√ßar a regulariza√ß√£o.
                - **Fun√ß√£o:**
                  Similar √† primeira camada Dropout.
                - **Exemplo no Modelo:**
                  ```python
                  Dropout(0.4)
                  ```
                  - **0.4:** 40% dos neur√¥nios ser√£o desligados.

                **6. MaxPooling1D_1 (MaxPooling1D)**
                - **O que √©?**
                  Segunda camada de max pooling para continuar a reduzir a dimensionalidade.
                - **Fun√ß√£o:**
                  Similar √† primeira camada MaxPooling1D.
                - **Exemplo no Modelo:**
                  ```python
                  MaxPooling1D(pool_size=4)
                  ```
                  - **pool_size=4:** Seleciona o maior valor em janelas de 4 unidades.

                **7. Flatten (Flatten)**
                - **O que √©?**
                  Flatten √© uma camada que transforma os dados multidimensionais em um vetor unidimensional.
                - **Fun√ß√£o:**
                  **Preparar para Camadas Densas:** Converte a sa√≠da das camadas convolucionais em uma forma adequada para as camadas densas (totalmente conectadas).
                - **Exemplo no Modelo:**
                  ```python
                  Flatten()
                  ```
                  - Sem par√¢metros, apenas altera a forma dos dados.

                **8. Dense (Dense)**
                - **O que √©?**
                  Dense √© uma camada totalmente conectada onde cada neur√¥nio est√° conectado a todos os neur√¥nios da camada anterior.
                - **Fun√ß√£o:**
                  **Tomar Decis√µes Finais:** Combina todas as caracter√≠sticas extra√≠das pelas camadas anteriores para fazer a classifica√ß√£o final.
                - **Exemplo no Modelo:**
                  ```python
                  Dense(64, activation='relu')
                  ```
                  - **64:** N√∫mero de neur√¥nios na camada.
                  - **activation='relu':** Fun√ß√£o de ativa√ß√£o que introduz n√£o-linearidade.

                **9. Dropout_2 (Dropout)**
                - **O que √©?**
                  Terceira camada de dropout para prevenir overfitting.
                - **Fun√ß√£o:**
                  Similar √†s camadas Dropout anteriores.
                - **Exemplo no Modelo:**
                  ```python
                  Dropout(0.4)
                  ```
                  - **0.4:** 40% dos neur√¥nios ser√£o desligados.

                **10. Dense_1 (Dense)**
                - **O que √©?**
                  Camada de sa√≠da que gera as probabilidades de cada classe usando a fun√ß√£o de ativa√ß√£o softmax.
                - **Fun√ß√£o:**
                  **Gera√ß√£o das Probabilidades:** Transforma as sa√≠das das camadas densas em probabilidades para cada classe.
                - **Exemplo no Modelo:**
                  ```python
                  Dense(len(classes), activation='softmax')
                  ```
                  - **len(classes):** N√∫mero de classes a serem classificadas.
                  - **activation='softmax':** Fun√ß√£o de ativa√ß√£o que transforma as sa√≠das em probabilidades.
                """)

            # Defini√ß√£o dos Callbacks
            st.write("### Configurando Callbacks para o Treinamento...")
            st.write("""
            **Callbacks** s√£o fun√ß√µes que s√£o chamadas durante o treinamento da rede neural. Elas podem ser usadas para monitorar o desempenho do modelo e ajustar o treinamento de acordo com certos crit√©rios. Nesta aplica√ß√£o, utilizamos dois callbacks:
            - **ModelCheckpoint:** Salva o modelo automaticamente quando a m√©trica de valida√ß√£o melhora.
            - **EarlyStopping:** Interrompe o treinamento automaticamente se a m√©trica de valida√ß√£o n√£o melhorar ap√≥s um n√∫mero especificado de √©pocas, evitando overfitting.
            """)

            from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
            diretorio_salvamento = 'modelos_salvos'
            if not os.path.exists(diretorio_salvamento):
                os.makedirs(diretorio_salvamento)
                st.write(f"**Diret√≥rio '{diretorio_salvamento}' criado para salvamento do modelo.**")
            else:
                st.write(f"**Diret√≥rio '{diretorio_salvamento}' j√° existe.**")

            # Configura√ß√£o do ModelCheckpoint
            checkpointer = ModelCheckpoint(
                filepath=os.path.join(diretorio_salvamento, 'modelo_agua_aumentado.keras'),  # Pode usar .h5 se preferir
                monitor='val_loss',
                verbose=1,
                save_best_only=True
            )

            # Par√¢metros de EarlyStopping
            st.sidebar.subheader("Par√¢metros de EarlyStopping")
            es_monitor = st.sidebar.selectbox(
                "Monitorar:",
                options=["val_loss", "val_accuracy"],
                index=0,
                help="M√©trica a ser monitorada para EarlyStopping. 'val_loss' monitora a perda na valida√ß√£o, enquanto 'val_accuracy' monitora a acur√°cia na valida√ß√£o."
            )
            es_patience = st.sidebar.slider(
                "Paci√™ncia (√âpocas):",
                min_value=1,
                max_value=20,
                value=5,
                step=1,
                help="N√∫mero de √©pocas sem melhoria antes de interromper o treinamento. Por exemplo, se 'patience' for 5, o treinamento ser√° interrompido ap√≥s 5 √©pocas sem melhoria na m√©trica monitorada."
            )
            es_mode = st.sidebar.selectbox(
                "Modo:",
                options=["min", "max"],
                index=0,
                help="Define se a m√©trica monitorada deve ser minimizada ('min') ou maximizada ('max'). 'val_loss' deve ser minimizada, enquanto 'val_accuracy' deve ser maximizada."
            )

            earlystop = EarlyStopping(
                monitor=es_monitor,
                patience=es_patience,
                restore_best_weights=True,
                mode=es_mode
            )

            # Treinamento do Modelo
            st.write("### Iniciando o Treinamento do Modelo...")
            st.write("""
            O treinamento pode demorar algum tempo, dependendo do tamanho do seu conjunto de dados e dos par√¢metros selecionados. Durante o treinamento, as m√©tricas de perda e acur√°cia ser√£o exibidas para acompanhamento.
            """)
            with st.spinner('Treinando o modelo...'):
                historico = modelo.fit(
                    X_train_final, to_categorical(y_train_final),
                    epochs=num_epochs,
                    batch_size=batch_size,
                    validation_data=(X_val, to_categorical(y_val)),
                    callbacks=[checkpointer, earlystop],
                    class_weight=class_weight_dict,
                    verbose=1
                )
            st.success("Treinamento conclu√≠do com sucesso!")

            # Salvamento do Modelo e Classes
            st.write("### Download do Modelo Treinado e Arquivo de Classes")
            st.write("""
            Ap√≥s o treinamento, voc√™ pode baixar o modelo treinado e o arquivo de classes para utiliza√ß√£o futura ou para compartilhar com outros.
            """)

            # Salvar o modelo em um arquivo tempor√°rio com extens√£o .keras
            with tempfile.NamedTemporaryFile(suffix='.keras', delete=False) as tmp_model:
                modelo.save(tmp_model.name)
                caminho_tmp_model = tmp_model.name

            # Ler o modelo salvo e preparar para download
            with open(caminho_tmp_model, 'rb') as f:
                modelo_bytes = f.read()

            buffer = io.BytesIO(modelo_bytes)

            st.download_button(
                label="Download do Modelo Treinado (.keras)",
                data=buffer,
                file_name="modelo_agua_aumentado.keras",
                mime="application/octet-stream"
            )

            # Remove o arquivo tempor√°rio ap√≥s o download
            os.remove(caminho_tmp_model)

            # Salvar as classes
            classes_str = "\n".join(classes)
            st.download_button(
                label="Download das Classes (classes.txt)",
                data=classes_str,
                file_name="classes.txt",
                mime="text/plain"
            )

            # Avalia√ß√£o do Modelo
            st.write("### Avalia√ß√£o do Modelo nos Conjuntos de Treino, Valida√ß√£o e Teste")
            st.write("""
            A seguir, apresentamos a **Acur√°cia** do modelo nos conjuntos de treino, valida√ß√£o e teste. A acur√°cia representa a porcentagem de previs√µes corretas realizadas pelo modelo.
            """)
            score_train = modelo.evaluate(X_train_final, to_categorical(y_train_final), verbose=0)
            score_val = modelo.evaluate(X_val, to_categorical(y_val), verbose=0)
            score_test = modelo.evaluate(X_test, to_categorical(y_test), verbose=0)

            st.write(f"**Acur√°cia no Treino:** {score_train[1]*100:.2f}%")
            st.write(f"**Acur√°cia na Valida√ß√£o:** {score_val[1]*100:.2f}%")
            st.write(f"**Acur√°cia no Teste:** {score_test[1]*100:.2f}%")

            # **Explica√ß√£o da Avalia√ß√£o**
            with st.expander("üìñ Explica√ß√£o da Avalia√ß√£o do Modelo"):
                st.markdown("""
                **Conclus√£o**

                Entender os dados e as camadas do modelo √© fundamental para interpretar como o modelo est√° aprendendo e realizando as classifica√ß√µes. 

                - **Shapes dos Dados:**
                  - Representam a estrutura dos dados em diferentes etapas do processamento e treinamento.
                  - Ajustar corretamente as dimens√µes √© crucial para que o modelo possa processar os dados de forma eficiente.

                - **Camadas do Modelo:**
                  - Cada camada tem uma fun√ß√£o espec√≠fica que contribui para a extra√ß√£o e processamento das informa√ß√µes necess√°rias para a classifica√ß√£o.
                  - **Conv1D** detecta padr√µes, **Dropout** previne overfitting, **MaxPooling1D** reduz a dimensionalidade, **Flatten** prepara os dados para a camada densa, e **Dense** realiza a classifica√ß√£o final.

                Compreender esses conceitos permite ajustar e otimizar o modelo de forma mais eficaz, melhorando sua performance e capacidade de generaliza√ß√£o.
                """)

            # Predi√ß√µes no Conjunto de Teste
            y_pred = modelo.predict(X_test)
            y_pred_classes = y_pred.argmax(axis=1)
            y_true = y_test  # y_test j√° est√° em formato inteiro

            # Matriz de Confus√£o com Seaborn
            st.write("""
            ### Matriz de Confus√£o
            A **Matriz de Confus√£o** mostra como as previs√µes do modelo se comparam com os r√≥tulos reais. Cada c√©lula representa o n√∫mero de previs√µes para cada combina√ß√£o de classe real e prevista.
            """)
            cm = confusion_matrix(y_true, y_pred_classes, labels=range(len(classes)))
            cm_df = pd.DataFrame(cm, index=classes, columns=classes)
            fig_cm, ax_cm = plt.subplots(figsize=(12,8))
            sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=ax_cm)
            ax_cm.set_title("Matriz de Confus√£o", fontsize=16)
            ax_cm.set_xlabel("Classe Prevista", fontsize=14)
            ax_cm.set_ylabel("Classe Real", fontsize=14)
            ax_cm.tick_params(axis='both', which='major', labelsize=12)
            st.pyplot(fig_cm)
            plt.close(fig_cm)

            # Relat√≥rio de Classifica√ß√£o com Seaborn
            st.write("""
            ### Relat√≥rio de Classifica√ß√£o
            O **Relat√≥rio de Classifica√ß√£o** fornece m√©tricas detalhadas sobre o desempenho do modelo em cada classe, incluindo precis√£o, recall e F1-score.
            """)
            report = classification_report(y_true, y_pred_classes, labels=range(len(classes)),
                                           target_names=classes, zero_division=0, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df)

            # Visualiza√ß√µes das M√©tricas de Treinamento com Seaborn
            st.write("""
            ### Visualiza√ß√µes das M√©tricas de Treinamento
            As seguintes figuras mostram como a **Perda (Loss)** e a **Acur√°cia** evolu√≠ram durante o treinamento e valida√ß√£o. Isso ajuda a entender como o modelo est√° aprendendo ao longo das √©pocas.
            """)
            historico_df = pd.DataFrame(historico.history)
            fig_loss, ax_loss = plt.subplots(figsize=(10,6))
            sns.lineplot(data=historico_df[['loss', 'val_loss']], ax=ax_loss)
            ax_loss.set_title("Perda (Loss) durante o Treinamento", fontsize=16)
            ax_loss.set_xlabel("√âpoca", fontsize=14)
            ax_loss.set_ylabel("Loss", fontsize=14)
            ax_loss.tick_params(axis='both', which='major', labelsize=12)
            st.pyplot(fig_loss)
            plt.close(fig_loss)

            fig_acc, ax_acc = plt.subplots(figsize=(10,6))
            sns.lineplot(data=historico_df[['accuracy', 'val_accuracy']], ax=ax_acc)
            ax_acc.set_title("Acur√°cia durante o Treinamento", fontsize=16)
            ax_acc.set_xlabel("√âpoca", fontsize=14)
            ax_acc.set_ylabel("Acur√°cia", fontsize=14)
            ax_acc.tick_params(axis='both', which='major', labelsize=12)
            st.pyplot(fig_acc)
            plt.close(fig_acc)

            # Limpeza de Mem√≥ria
            del modelo, historico, historico_df
            gc.collect()

            st.success("Processo de Treinamento e Avalia√ß√£o conclu√≠do!")

            # Remo√ß√£o dos arquivos tempor√°rios
            os.remove(caminho_zip)
            for cat in categorias:
                caminho_cat = os.path.join(caminho_base, cat)
                for arquivo in os.listdir(caminho_cat):
                    os.remove(os.path.join(caminho_cat, arquivo))
                os.rmdir(caminho_cat)
            os.rmdir(caminho_base)

        except Exception as e:
            st.error(f"Erro durante o processamento do dataset: {e}")
            # Assegura a remo√ß√£o dos arquivos tempor√°rios em caso de erro
            if 'caminho_zip' in locals() and os.path.exists(caminho_zip):
                os.remove(caminho_zip)
            if 'caminho_base' in locals() and os.path.exists(caminho_base):
                for cat in categorias:
                    caminho_cat = os.path.join(caminho_base, cat)
                    for arquivo in os.listdir(caminho_cat):
                        os.remove(os.path.join(caminho_cat, arquivo))
                    os.rmdir(caminho_cat)
                os.rmdir(caminho_base)

if __name__ == "__main__":
    main()
