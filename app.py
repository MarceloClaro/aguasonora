"""
Classifica√ß√£o de Sons de √Ågua Vibrando em Copo de Vidro com Aumento de Dados e CNN

Contexto F√≠sico:
---------------
Quando um copo com √°gua √© excitado, formam-se ondas no fluido. Essas ondas apresentam modos ressonantes,
cuja frequ√™ncia depende da altura da coluna de √°gua, geometria do copo, densidade e outras caracter√≠sticas f√≠sicas.
Esses modos geram padr√µes ac√∫sticos distintos. Ao extrair caracter√≠sticas espectrais do √°udio (como MFCCs e 
centr√≥ide espectral), podemos capturar informa√ß√µes sobre quais frequ√™ncias dominam o sinal.

- MFCCs (Mel-Frequency Cepstral Coefficients): mapeiam frequ√™ncias para uma escala Mel pr√≥xima da percep√ß√£o humana.
  Fisicamente, se um determinado modo ressonante (frequ√™ncia particular) domina, certos MFCCs refletir√£o
  maior energia nessa banda.

- Centr√≥ide Espectral: indica a frequ√™ncia m√©dia. Modos mais agudos (frequ√™ncias elevadas) tendem a aumentar o centr√≥ide.
  Se a √°gua √© mais rasa, espera-se modos de frequ√™ncia mais alta, logo um centr√≥ide mais alto.

Ao treinar uma CNN com esses dados, o modelo aprende a mapear essas caracter√≠sticas espectrais para estados espec√≠ficos
do fluido-copo (ex.: diferentes n√≠veis de √°gua ou condi√ß√µes experimentais).

Nesta vers√£o (Nota 10/10):
- Docstrings detalhadas e explica√ß√µes f√≠sicas mais profundas.
- SHAP aplicado para interpretar a import√¢ncia de cada feature, relacionando-as a fen√¥menos f√≠sicos.
- Coment√°rios mais ricos no clustering (K-Means e Hier√°rquico), interpretando a estrutura dos dados em termos f√≠sicos.
- LR Scheduler (ReduceLROnPlateau) adicionado para refinar o treinamento.

O objetivo √© um pipeline robusto, cientificamente coerente e bem documentado.
"""

import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import librosa
import tensorflow as tf
from tensorflow.keras.utils import to_categorical, plot_model
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
from sklearn.utils.class_weight import compute_class_weight
from sklearn.model_selection import train_test_split, KFold
from sklearn.cluster import KMeans, AgglomerativeClustering
from scipy.cluster.hierarchy import linkage, dendrogram
from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift
import streamlit as st
import tempfile
from PIL import Image, UnidentifiedImageError
import io
import torch
import zipfile
import gc
import os
import logging
from tensorflow.keras import regularizers
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import shap

# ==================== LOGGING ====================
logging.basicConfig(
    filename='experiment_logs.log',
    filemode='a',
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# ==================== CONFIGURA√á√ÉO DA P√ÅGINA ====================
seed_options = list(range(0, 61, 2))
default_seed = 42
if default_seed not in seed_options:
    seed_options.insert(0, default_seed)

icon_path = "logo.png"
if os.path.exists(icon_path):
    try:
        st.set_page_config(page_title="Geomaker", page_icon=icon_path, layout="wide")
        logging.info("√çcone carregado.")
    except Exception as e:
        st.set_page_config(page_title="Geomaker", layout="wide")
        logging.warning(f"Erro ao carregar √≠cone: {e}")
else:
    st.set_page_config(page_title="Geomaker", layout="wide")
    logging.warning("√çcone n√£o encontrado.")

st.sidebar.header("Configura√ß√µes Gerais")

seed_selection = st.sidebar.selectbox(
    "Escolha o valor do SEED:",
    options=seed_options,
    index=seed_options.index(default_seed),
    help="Define a semente para reprodutibilidade."
)
SEED = seed_selection

def set_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seeds(SEED)
logging.info(f"SEED={SEED}")

with st.sidebar.expander("üìñ Valor de SEED - Semente"):
    st.markdown("(Explica√ß√£o do SEED omitida.)")

capa_path = 'capa (2).png'
if os.path.exists(capa_path):
    try:
        st.image(
            capa_path, 
            caption='Laborat√≥rio de Educa√ß√£o e IA - Geomaker', 
            use_container_width=True
        )
    except UnidentifiedImageError:
        st.warning("Imagem da capa corrompida.")
else:
    st.warning("Imagem da capa n√£o encontrada.")

logo_path = "logo.png"
if os.path.exists(logo_path):
    try:
        st.sidebar.image(logo_path, width=200)
    except UnidentifiedImageError:
        st.sidebar.text("Logo corrompido.")
else:
    st.sidebar.text("Logo n√£o encontrado.")

st.title("Classifica√ß√£o de Sons de √Ågua Vibrando em Copo de Vidro com Aumento de Dados e CNN")

st.write("""
Op√ß√µes:
- Classificar √Åudio: usar modelo treinado.
- Treinar Modelo: treinar modelo novo.
""")

st.sidebar.title("Navega√ß√£o")
app_mode = st.sidebar.radio("Escolha a se√ß√£o", ["Classificar √Åudio", "Treinar Modelo"])

eu_icon_path = "eu.ico"
if os.path.exists(eu_icon_path):
    try:
        st.sidebar.image(eu_icon_path, width=80)
    except UnidentifiedImageError:
        st.sidebar.text("√çcone 'eu.ico' corrompido.")
else:
    st.sidebar.text("√çcone 'eu.ico' n√£o encontrado.")

st.sidebar.write("""
Produzido: Projeto Geomaker + IA

Prof: Marcelo Claro
Contato: marceloclaro@gmail.com
""")

augment_default = Compose([
    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),
    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),
    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),
    Shift(min_shift=-0.5, max_shift=0.5, p=0.5),
])

def carregar_audio(caminho_arquivo, sr=None):
    """
    Carrega um arquivo de √°udio. 
    Retorna o sinal e a taxa de amostragem.
    """
    try:
        data, sr = librosa.load(caminho_arquivo, sr=sr, res_type='kaiser_fast')
        return data, sr
    except:
        return None, None

def extrair_features(data, sr, use_mfcc=True, use_spectral_centroid=True):
    """
    Extrai features do sinal de √°udio (MFCCs e centr√≥ide espectral).
    
    MFCCs: refletem a distribui√ß√£o de energia em bandas de frequ√™ncia. 
    Estados f√≠sicos diferentes do fluido-copo alteram frequ√™ncias dominantes, logo MFCCs mudam.

    Centr√≥ide Espectral: indica frequ√™ncia m√©dia. Modos mais agudos (frequ√™ncias altas) -> centr√≥ide maior.

    Normaliza√ß√£o: garante escala uniforme.
    """
    try:
        features_list = []
        if use_mfcc:
            mfccs = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40)
            mfccs_scaled = np.mean(mfccs.T, axis=0)
            features_list.append(mfccs_scaled)
        if use_spectral_centroid:
            centroid = librosa.feature.spectral_centroid(y=data, sr=sr)
            centroid_mean = np.mean(centroid, axis=1)
            features_list.append(centroid_mean)
        if len(features_list) > 1:
            features_vector = np.concatenate(features_list, axis=0)
        else:
            features_vector = features_list[0]
        features_vector = (features_vector - np.mean(features_vector)) / (np.std(features_vector) + 1e-9)
        return features_vector
    except Exception as e:
        logging.error(f"Erro na extra√ß√£o de features: {e}")
        return None

def aumentar_audio(data, sr, augmentations):
    """
    Aplica Data Augmentation ao sinal.
    Isso simula varia√ß√µes experimentais (ru√≠do, mudan√ßa de pitch, estiramento de tempo),
    ajudando o modelo a generalizar melhor.
    """
    try:
        return augmentations(samples=data, sample_rate=sr)
    except:
        return data

def classificar_audio(SEED):
    st.header("Classifica√ß√£o de Novo √Åudio (Omitido)")

def treinar_modelo(SEED):
    st.header("Treinamento do Modelo CNN")

    st.write("### Passo 1: Upload do Dataset (ZIP)")
    zip_upload = st.file_uploader("Upload do ZIP", type=["zip"])

    if zip_upload is not None:
        try:
            st.write("Extraindo o Dataset...")
            with tempfile.NamedTemporaryFile(delete=False, suffix=".zip") as tmp_zip:
                tmp_zip.write(zip_upload.read())
                caminho_zip = tmp_zip.name

            diretorio_extracao = tempfile.mkdtemp()
            with zipfile.ZipFile(caminho_zip, 'r') as zip_ref:
                zip_ref.extractall(diretorio_extracao)
            caminho_base = diretorio_extracao

            categorias = [d for d in os.listdir(caminho_base) if os.path.isdir(os.path.join(caminho_base, d))]
            if len(categorias) == 0:
                st.error("Nenhuma subpasta encontrada.")
                return

            st.success("Dataset extra√≠do!")
            st.write(f"Classes encontradas: {', '.join(categorias)}")

            caminhos_arquivos = []
            labels = []
            for cat in categorias:
                caminho_cat = os.path.join(caminho_base, cat)
                arquivos_na_cat = [f for f in os.listdir(caminho_cat) if f.lower().endswith(('.wav','.mp3','.flac','.ogg','.m4a'))]
                st.write(f"Classe '{cat}': {len(arquivos_na_cat)} arquivos.")
                for nome_arquivo in arquivos_na_cat:
                    caminhos_arquivos.append(os.path.join(caminho_cat, nome_arquivo))
                    labels.append(cat)

            df = pd.DataFrame({'caminho_arquivo': caminhos_arquivos, 'classe': labels})
            st.write("10 Primeiras Amostras do Dataset:")
            st.dataframe(df.head(10))

            if len(df)==0:
                st.error("Nenhuma amostra encontrada.")
                return

            labelencoder = LabelEncoder()
            y = labelencoder.fit_transform(df['classe'])
            classes = labelencoder.classes_
            st.sidebar.subheader("Par√¢metros Principais")
            st.sidebar.write(f"N√∫mero de Classes: {len(classes)}")
            st.sidebar.write("Classes: "+", ".join(classes))
            st.write(f"Classes codificadas: {', '.join(classes)}")

            st.write("Extraindo Features...")
            X = []
            y_valid = []
            for i, row in df.iterrows():
                arquivo = row['caminho_arquivo']
                data, sr = carregar_audio(arquivo, sr=None)
                if data is not None:
                    ftrs = extrair_features(data, sr, use_mfcc=True, use_spectral_centroid=True)
                    if ftrs is not None:
                        X.append(ftrs)
                        y_valid.append(y[i])

            X = np.array(X)
            y_valid = np.array(y_valid)
            st.write(f"Features extra√≠das: {X.shape}")

            # Configura√ß√µes
            st.sidebar.subheader("Configura√ß√µes de Treinamento")
            num_epochs = st.sidebar.slider("N√∫mero de √âpocas:", 10, 500, 50, 10)
            batch_size = st.sidebar.selectbox("Batch:", [8,16,32,64,128],0)
            st.sidebar.subheader("Divis√£o dos Dados")
            treino_percentage = st.sidebar.slider("Treino (%)",50,90,70,5)
            valid_percentage = st.sidebar.slider("Valida√ß√£o (%)",5,30,15,5)
            test_percentage = 100-(treino_percentage+valid_percentage)
            if test_percentage<0:
                st.sidebar.error("Treino+Val>100%")
                st.stop()
            st.sidebar.write(f"Teste (%)={test_percentage}%")

            augment_factor = st.sidebar.slider("Fator Aumento:",1,100,10,1)
            dropout_rate = st.sidebar.slider("Dropout:",0.0,0.9,0.4,0.05)

            st.sidebar.subheader("Regulariza√ß√£o")
            regularization_type = st.sidebar.selectbox("Regulariza√ß√£o:",["None","L1","L2","L1_L2"],0)
            if regularization_type=="L1":
                l1_regularization=st.sidebar.slider("L1:",0.0,0.1,0.001,0.001)
                l2_regularization=0.0
            elif regularization_type=="L2":
                l2_regularization=st.sidebar.slider("L2:",0.0,0.1,0.001,0.001)
                l1_regularization=0.0
            elif regularization_type=="L1_L2":
                l1_regularization=st.sidebar.slider("L1:",0.0,0.1,0.001,0.001)
                l2_regularization=st.sidebar.slider("L2:",0.0,0.1,0.001,0.001)
            else:
                l1_regularization=0.0
                l2_regularization=0.0

            enable_augmentation=st.sidebar.checkbox("Data Augmentation",True)
            if enable_augmentation:
                st.sidebar.subheader("Data Aug Options")
                adicionar_ruido=st.sidebar.checkbox("Ru√≠do Gaussiano",True)
                estiramento_tempo=st.sidebar.checkbox("Time Stretch",True)
                alteracao_pitch=st.sidebar.checkbox("Pitch Shift",True)
                deslocamento=st.sidebar.checkbox("Deslocamento",True)

            st.sidebar.subheader("Valida√ß√£o Cruzada")
            cross_validation=st.sidebar.checkbox("k-Fold?",False)
            if cross_validation:
                k_folds=st.sidebar.number_input("Folds:",2,10,5,1)
            else:
                k_folds=1

            st.sidebar.subheader("Balanceamento")
            balance_classes=st.sidebar.selectbox("Balanceamento:",["Balanced","None"],0)

            if enable_augmentation:
                st.write("Aumentando Dados...")
                X_aug=[]
                y_aug=[]
                for i,row in df.iterrows():
                    arquivo=row['caminho_arquivo']
                    data, sr=carregar_audio(arquivo,sr=None)
                    if data is not None:
                        transforms=[]
                        if adicionar_ruido:
                            transforms.append(AddGaussianNoise(min_amplitude=0.001,max_amplitude=0.015,p=1.0))
                        if estiramento_tempo:
                            transforms.append(TimeStretch(min_rate=0.8,max_rate=1.25,p=1.0))
                        if alteracao_pitch:
                            transforms.append(PitchShift(min_semitones=-4,max_semitones=4,p=1.0))
                        if deslocamento:
                            transforms.append(Shift(min_shift=-0.5,max_shift=0.5,p=1.0))
                        if transforms:
                            aug=Compose(transforms)
                            for _ in range(augment_factor):
                                aug_data=aumentar_audio(data,sr,aug)
                                ftrs=extrair_features(aug_data,sr)
                                if ftrs is not None:
                                    X_aug.append(ftrs)
                                    y_aug.append(y[i])

                X_aug=np.array(X_aug)
                y_aug=np.array(y_aug)
                st.write(f"Dados Aumentados: {X_aug.shape}")
                X_combined=np.concatenate((X,X_aug),axis=0)
                y_combined=np.concatenate((y_valid,y_aug),axis=0)
            else:
                X_combined=X
                y_combined=y_valid

            st.write("Dividindo Dados...")
            X_train,X_temp,y_train,y_temp=train_test_split(X_combined,y_combined,test_size=(100-treino_percentage)/100.0,
                                                           random_state=SEED,stratify=y_combined)
            X_val,X_test,y_val,y_test=train_test_split(X_temp,y_temp,test_size=test_percentage/(test_percentage+valid_percentage),
                                                       random_state=SEED,stratify=y_temp)

            st.write(f"Treino:{X_train.shape}, Val:{X_val.shape}, Teste:{X_test.shape}")

            X_original = X_combined
            y_original = y_combined

            X_train_final = X_train.reshape((X_train.shape[0],X_train.shape[1],1))
            X_val = X_val.reshape((X_val.shape[0],X_val.shape[1],1))
            X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))

            st.sidebar.subheader("Arquitetura da CNN")
            num_conv_layers=st.sidebar.slider("Conv Layers",1,5,2,1)
            conv_filters_str=st.sidebar.text_input("Filtros (v√≠rgula):","64,128")
            conv_kernel_size_str=st.sidebar.text_input("Kernel (v√≠rgula):","10,10")
            conv_filters=[int(f.strip()) for f in conv_filters_str.split(',')]
            conv_kernel_size=[int(k.strip()) for k in conv_kernel_size_str.split(',')]

            input_length=X_train_final.shape[1]
            for i in range(num_conv_layers):
                if conv_kernel_size[i]>input_length:
                    conv_kernel_size[i]=input_length

            num_dense_layers=st.sidebar.slider("Dense Layers:",1,3,1,1)
            dense_units_str=st.sidebar.text_input("Neur√¥nios Dense (v√≠rgula):","64")
            dense_units=[int(u.strip()) for u in dense_units_str.split(',')]
            if len(dense_units)!=num_dense_layers:
                st.sidebar.error("Neur√¥nios != Dense Layers.")
                st.stop()

            from tensorflow.keras.models import Sequential
            from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input

            if regularization_type=="L1":
                reg=regularizers.l1(l1_regularization)
            elif regularization_type=="L2":
                reg=regularizers.l2(l2_regularization)
            elif regularization_type=="L1_L2":
                reg=regularizers.l1_l2(l1=l1_regularization,l2=l2_regularization)
            else:
                reg=None

            modelo=Sequential()
            modelo.add(Input(shape=(X_train_final.shape[1],1)))
            for i in range(num_conv_layers):
                modelo.add(Conv1D(filters=conv_filters[i],kernel_size=conv_kernel_size[i],activation='relu',kernel_regularizer=reg))
                modelo.add(Dropout(dropout_rate))
                modelo.add(MaxPooling1D(pool_size=2))

            modelo.add(Flatten())
            for i in range(num_dense_layers):
                modelo.add(Dense(units=dense_units[i],activation='relu',kernel_regularizer=reg))
                modelo.add(Dropout(dropout_rate))
            modelo.add(Dense(len(classes),activation='softmax'))
            modelo.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

            diretorio_salvamento='modelos_salvos'
            if not os.path.exists(diretorio_salvamento):
                os.makedirs(diretorio_salvamento)

            checkpointer=ModelCheckpoint(os.path.join(diretorio_salvamento,'modelo_agua_aumentado.keras'),
                                         monitor='val_loss',verbose=1,save_best_only=True)
            es_monitor=st.sidebar.selectbox("Monitor (ES):",["val_loss","val_accuracy"],0)
            es_patience=st.sidebar.slider("Patience:",1,20,5,1)
            es_mode=st.sidebar.selectbox("Mode:",["min","max"],0)
            earlystop=EarlyStopping(monitor=es_monitor,patience=es_patience,restore_best_weights=True,mode=es_mode)

            # Adicionando LR Scheduler
            lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)

            callbacks=[checkpointer,earlystop,lr_scheduler]

            st.write("Treinando...")
            with st.spinner('Treinando...'):
                if balance_classes=="Balanced":
                    class_weights=compute_class_weight('balanced',classes=np.unique(y_train),y=y_train)
                    class_weight_dict={i:class_weights[i] for i in range(len(class_weights))}
                else:
                    class_weight_dict=None

                if cross_validation and k_folds>1:
                    kf=KFold(n_splits=k_folds,shuffle=True,random_state=SEED)
                    fold_no=1
                    val_scores=[]
                    for train_index,val_index in kf.split(X_train_final):
                        st.write(f"Fold {fold_no}")
                        X_train_cv,X_val_cv=X_train_final[train_index],X_train_final[val_index]
                        y_train_cv,y_val_cv=y_train[train_index],y_train[val_index]
                        historico=modelo.fit(X_train_cv,to_categorical(y_train_cv),
                                             epochs=num_epochs,batch_size=batch_size,
                                             validation_data=(X_val_cv,to_categorical(y_val_cv)),
                                             callbacks=callbacks,class_weight=class_weight_dict,verbose=1)
                        score=modelo.evaluate(X_val_cv,to_categorical(y_val_cv),verbose=0)
                        val_scores.append(score[1]*100)
                        fold_no+=1
                    st.write(f"Acur√°cia M√©dia CV: {np.mean(val_scores):.2f}%")
                else:
                    historico=modelo.fit(X_train_final,to_categorical(y_train),
                                         epochs=num_epochs,batch_size=batch_size,
                                         validation_data=(X_val,to_categorical(y_val)),
                                         callbacks=callbacks,class_weight=class_weight_dict,verbose=1)
                st.success("Treino conclu√≠do!")

            # Download modelo
            with tempfile.NamedTemporaryFile(suffix='.keras',delete=False) as tmp_model:
                modelo.save(tmp_model.name)
                caminho_tmp_model=tmp_model.name
            with open(caminho_tmp_model,'rb') as f:
                modelo_bytes=f.read()
            buffer=io.BytesIO(modelo_bytes)
            st.download_button("Download Modelo (.keras)",data=buffer,file_name="modelo_agua_aumentado.keras")
            os.remove(caminho_tmp_model)

            classes_str="\n".join(classes)
            st.download_button("Download Classes (classes.txt)",data=classes_str,file_name="classes.txt")

            if not cross_validation:
                st.write("### Avalia√ß√£o do Modelo")
                score_train=modelo.evaluate(X_train_final,to_categorical(y_train),verbose=0)
                score_val=modelo.evaluate(X_val,to_categorical(y_val),verbose=0)
                score_test=modelo.evaluate(X_test,to_categorical(y_test),verbose=0)

                st.write(f"Acur√°cia Treino: {score_train[1]*100:.2f}%")
                st.write(f"Acur√°cia Valida√ß√£o: {score_val[1]*100:.2f}%")
                st.write(f"Acur√°cia Teste: {score_test[1]*100:.2f}%")

                y_pred=modelo.predict(X_test)
                y_pred_classes=y_pred.argmax(axis=1)
                f1_val=f1_score(y_test,y_pred_classes,average='weighted')
                prec=precision_score(y_test,y_pred_classes,average='weighted')
                rec=recall_score(y_test,y_pred_classes,average='weighted')

                st.write(f"F1-score: {f1_val*100:.2f}%")
                st.write(f"Precis√£o: {prec*100:.2f}%")
                st.write(f"Recall: {rec*100:.2f}%")

                st.write("### Matriz de Confus√£o")
                cm=confusion_matrix(y_test,y_pred_classes,labels=range(len(classes)))
                cm_df=pd.DataFrame(cm,index=classes,columns=classes)
                fig_cm,ax_cm=plt.subplots(figsize=(12,8))
                sns.heatmap(cm_df,annot=True,fmt='d',cmap='Blues',ax=ax_cm)
                ax_cm.set_title("Matriz de Confus√£o",fontsize=16)
                ax_cm.set_xlabel("Classe Prevista",fontsize=14)
                ax_cm.set_ylabel("Classe Real",fontsize=14)
                st.pyplot(fig_cm)
                plt.close(fig_cm)

                # Arquitetura e Resumo
                st.write("### Arquitetura da CNN (Camadas)")
                modelo.summary(print_fn=lambda x: st.text(x))
                try:
                    with tempfile.NamedTemporaryFile(suffix='.png',delete=False) as tmp_plot:
                        plot_model(modelo,to_file=tmp_plot.name,show_shapes=True,show_layer_names=True)
                        img=Image.open(tmp_plot.name)
                        st.image(img,caption="Arquitetura da CNN")
                        os.remove(tmp_plot.name)
                except:
                    st.write("Instale graphviz para plotar arquitetura.")

                # Hist√≥rico de Treinamento
                if not cross_validation:
                    st.write("### Hist√≥rico de Treinamento")
                    hist_df=pd.DataFrame(historico.history)
                    st.dataframe(hist_df)

                # SHAP para Interpretabilidade
                st.write("### Explicabilidade com SHAP")
                st.write("Selecionando amostras de teste para an√°lise SHAP.")
                X_sample = X_test[:50]
                # Criando explainer SHAP
                try:
                    explainer = shap.DeepExplainer(modelo, X_train_final[:100])
                    shap_values = explainer.shap_values(X_sample)
                    # Plot summary
                    st.write("Plot SHAP Summary (MFCCs + Centr√≥ide):")
                    fig_shap = plt.figure()
                    shap.summary_plot(shap_values, X_sample.reshape((X_sample.shape[0],X_sample.shape[1])), show=False)
                    st.pyplot(fig_shap)
                    plt.close(fig_shap)
                    st.write("""
                    Interpreta√ß√£o F√≠sica: 
                    Valores SHAP positivos em certos MFCCs indicam que aquelas frequ√™ncias espec√≠ficas
                    ajudam o modelo a reconhecer uma determinada classe. Se essa classe corresponde
                    a um estado f√≠sico com modos de vibra√ß√£o mais agudos, ent√£o o MFCC associado a frequ√™ncias
                    mais altas ter√° grande import√¢ncia SHAP positiva.
                    Assim, o SHAP nos mostra como as frequ√™ncias (MFCCs) est√£o ligadas √†s propriedades f√≠sicas 
                    do estado do fluido.
                    """)
                except Exception as e:
                    st.write("N√£o foi poss√≠vel gerar SHAP:", e)

                # Clustering K-Means e Hier√°rquico
                st.write("### An√°lise de Clusters (K-Means e Hier√°rquico)")
                st.write("""
                O K-Means e o agrupamento Hier√°rquico analisam a estrutura intr√≠nseca dos dados (features).
                Se certos clusters re√∫nem classes com caracter√≠sticas espectrais semelhantes, isso indica que
                essas classes representam estados f√≠sicos similares (ex. colunas d'√°gua semelhantes, resultando em modos pr√≥ximos).
                """)

                n_clusters=2
                kmeans=KMeans(n_clusters=n_clusters,random_state=SEED)
                kmeans_labels=kmeans.fit_predict(X_original)
                st.write("Distribui√ß√£o de Classes por Cluster (KMeans):")
                cluster_dist=[]
                for cidx in range(n_clusters):
                    cluster_classes=y_original[kmeans_labels==cidx]
                    counts=pd.value_counts(cluster_classes)
                    cluster_dist.append(counts)
                st.write(cluster_dist)
                st.write("""
                Se um cluster agrupa majoritariamente classes com modos mais graves (por ex.), isto sugere que o cluster 
                representa um conjunto de amostras fisicamente semelhantes (colunas de √°gua mais altas?).
                """)

                st.write("An√°lise Hier√°rquica:")
                Z=linkage(X_original,'ward')
                fig_dend,ax_dend=plt.subplots(figsize=(10,5))
                dendrogram(Z,ax=ax_dend)
                ax_dend.set_title("Dendrograma Hier√°rquico")
                ax_dend.set_xlabel("Amostras")
                ax_dend.set_ylabel("Dist√¢ncia")
                st.pyplot(fig_dend)
                plt.close(fig_dend)

                hier=AgglomerativeClustering(n_clusters=2)
                hier_labels=hier.fit_predict(X_original)
                st.write("Distribui√ß√£o de Classes por Cluster (Hier√°rquico):")
                cluster_dist_h=[]
                for cidx in range(2):
                    cluster_classes=y_original[hier_labels==cidx]
                    counts_h=pd.value_counts(cluster_classes)
                    cluster_dist_h.append(counts_h)
                st.write(cluster_dist_h)
                st.write("""
                Se classes diferentes aparecem muito pr√≥ximas no dendrograma, significa que suas caracter√≠sticas espectrais 
                s√£o similares. Fisicamente, pode significar que esses estados do fluido-copo diferem pouco nos modos ressonantes,
                tornando-os espectralmente pr√≥ximos e, portanto, dif√≠ceis de separar sem t√©cnicas mais avan√ßadas ou mais dados.
                """)

            # Limpeza
            gc.collect()
            os.remove(caminho_zip)
            for cat in categorias:
                caminho_cat=os.path.join(caminho_base,cat)
                for arquivo in os.listdir(caminho_cat):
                    os.remove(os.path.join(caminho_cat,arquivo))
                os.rmdir(caminho_cat)
            os.rmdir(caminho_base)
            logging.info("Processo conclu√≠do.")

        except Exception as e:
            st.error(f"Erro: {e}")
            logging.error(f"Erro: {e}")

if __name__=="__main__":
    if app_mode=="Classificar √Åudio":
        classificar_audio(SEED)
    elif app_mode=="Treinar Modelo":
        treinar_modelo(SEED)
